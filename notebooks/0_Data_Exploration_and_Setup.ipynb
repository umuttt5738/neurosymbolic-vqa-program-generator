{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=ltr align=center>\n",
    "    <font color=0F5298 size=7>Neurosymbolic VQA Program Generator</font><br>\n",
    "    <br>\n",
    "    <font color=2565AE size=5>Part 0: Data Exploration & Setup</font><br>\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Why It Matters: Neurosymbolic VQA**\n",
    "\n",
    "This project builds a **Neurosymbolic** framework for Visual Question Answering (VQA). In this paradigm:\n",
    "\n",
    "- <span style=\"color:blue\">**Programs**</span> act as **symbols**. They represent a concrete, logical sequence of steps to find an answer (e.g., `scene` -> `filter_color[blue]` -> `count`).\n",
    "- <span style=\"color:green\">**Seq2Seq Models**</span> serve as **neural structures**. Their job is to learn the mapping from a flexible, ambiguous natural language question (like \"*how many blue things are there?*\") to a rigid, logical symbolic program.\n",
    "\n",
    "This combination gives us the best of both worlds: the **generalizability** of neural networks and the **interpretability** and **compositionality** of symbolic logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this project, we will have implemented and compared three distinct strategies for training the neural program generator:\n",
    "\n",
    "1.  ðŸŸ  **Supervised Learning**: Training a model (LSTM & Transformer) using the ground-truth programs. This is a form of \"behavioral cloning.\"\n",
    "2.  ðŸ”µ **Reinforcement Learning (RL)**: Fine-tuning the supervised model using rewards from a symbolic executor. The model gets a reward if its generated program produces the *correct answer*, even if the program itself isn't identical to the ground-truth one.\n",
    "3.  ðŸŸ¢ **In-Context Learning (ICL)**: Using a pre-trained Large Language Model (LLM) to generate programs by showing it a few examples in its prompt, with no explicit training or fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: **Download the CLEVR Dataset**\n",
    "\n",
    "First, you must download the CLEVR dataset from this link:\n",
    "\n",
    "**Link:** [https://drive.google.com/file/d/1_AtOysdMraIdLbbmAzC2x862Jd7xQDQ7/view?usp=sharing](https://drive.google.com/file/d/1_AtOysdMraIdLbbmAzC2x862Jd7xQDQ7/view?usp=sharing)\n",
    "\n",
    "1.  Download the `CELVR_Dataset.zip` file.\n",
    "2.  Unzip it.\n",
    "3.  Place the resulting `CELVR_Dataset` folder inside the `data/` directory of this project.\n",
    "\n",
    "The final structure should look like this:\n",
    "\n",
    "```bash\n",
    "    neurosymbolic-vqa-program-generator/\n",
    "    â”œâ”€â”€ data/\n",
    "    â”‚   â”œâ”€â”€ CELVR_Dataset/\n",
    "    â”‚   â”‚   â”œâ”€â”€ Questions/\n",
    "    â”‚   â”‚   â””â”€â”€ Scenses/  <-- (Note: original folder has a typo, change it to Scenes)\n",
    "    â”‚   â””â”€â”€ .gitkeep\n",
    "    â”œâ”€â”€ notebooks/\n",
    "    â”‚   â””â”€â”€ 0_Data_Exploration_and_Setup.ipynb\n",
    "    â””â”€â”€ src/\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: **Explore the Raw Data**\n",
    "\n",
    "Let's load one question and one scene to see what the raw data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Now we can import from our src package\n",
    "import src.config as config\n",
    "\n",
    "# --- Load an example question --- \n",
    "print(f\"Loading questions from: {config.TRAIN_QUESTIONS_JSON}\\n\")\n",
    "with open(config.TRAIN_QUESTIONS_JSON, 'r') as f:\n",
    "    question_data = json.load(f)['questions']\n",
    "\n",
    "print(\"--- Example Question (index 0) ---\")\n",
    "example_question = question_data[0]\n",
    "print(json.dumps(example_question, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load an example scene --- \n",
    "print(f\"Loading scenes from: {config.TRAIN_SCENES_JSON}\\n\")\n",
    "with open(config.TRAIN_SCENES_JSON, 'r') as f:\n",
    "    scene_data = json.load(f)['scenes']\n",
    "\n",
    "print(\"--- Example Scene (index 0) ---\")\n",
    "example_scene = scene_data[0]\n",
    "print(json.dumps(example_scene, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: **Preprocess the Data**\n",
    "\n",
    "The raw data is not in a format our models can use. We need to run the `preprocess_data.py` script to:\n",
    "\n",
    "1.  **Build a Vocabulary**: Create a mapping from tokens (like \"what\", \"blue\", \"filter_color\") to integer indices.\n",
    "2.  **Tokenize & Encode**: Convert all questions and programs into sequences of these integers.\n",
    "3.  **Pad**: Pad all sequences to a uniform length so they can be batched.\n",
    "4.  **Save to H5**: Store these large numerical arrays in an efficient H5 file.\n",
    "\n",
    "We will run this script three times: once for `train` (which *creates* the vocab) and once each for `val` and `test` (which *use* the saved vocab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 1. Preprocessing TRAIN data ---\")\n",
    "# This command builds the vocabulary and saves it\n",
    "!python ../scripts/preprocess_data.py \\\n",
    "    --input_json ../data/CLEVR_Dataset/Questions/CLEVR_train_questions.json \\\n",
    "    --output_h5 ../data/dataH5Files/clevr_train_questions.h5 \\\n",
    "    --output_vocab_json ../data/dataH5Files/clevr_vocab.json\n",
    "\n",
    "print(\"\\n--- 2. Preprocessing VALIDATION data ---\")\n",
    "# This command loads the existing vocab\n",
    "!python ../scripts/preprocess_data.py \\\n",
    "    --input_json ../data/CLEVR_Dataset/Questions/CLEVR_val_questions.json \\\n",
    "    --input_vocab_json ../data/dataH5Files/clevr_vocab.json \\\n",
    "    --output_h5 ../data/dataH5Files/clevr_val_questions.h5 \\\n",
    "    --allow_unk 1\n",
    "\n",
    "print(\"\\n--- 3. Preprocessing TEST data ---\")\n",
    "# This command also loads the existing vocab\n",
    "!python ../scripts/preprocess_data.py \\\n",
    "    --input_json ../data/CLEVR_Dataset/Questions/CLEVR_test_questions.json \\\n",
    "    --input_vocab_json ../data/dataH5Files/clevr_vocab.json \\\n",
    "    --output_h5 ../data/dataH5Files/clevr_test_questions.h5 \\\n",
    "    --allow_unk 1\n",
    "\n",
    "print(\"\\nPreprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: **Verify the Processed H5 File**\n",
    "\n",
    "Let's load the H5 file and our new vocabulary to make sure everything worked. We'll load the first processed question and program and decode them back to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "from src.vocabulary import load_vocab, decode\n",
    "\n",
    "# 1. Load the vocabulary\n",
    "vocab = load_vocab(config.VOCAB_JSON_FILE)\n",
    "\n",
    "# 2. Load the H5 file\n",
    "print(f\"Loading H5 file: {config.TRAIN_H5_FILE}\")\n",
    "with h5py.File(config.TRAIN_H5_FILE, 'r') as f:\n",
    "    question_vectors = f['questions']\n",
    "    program_vectors = f['programs']\n",
    "    \n",
    "    # Get the first question and program\n",
    "    q_vec = question_vectors[0]\n",
    "    p_vec = program_vectors[0]\n",
    "    \n",
    "    print(\"\\n--- Original Vectorized Question (index 0) ---\")\n",
    "    print(q_vec)\n",
    "    print(\"\\n--- Decoded Question ---\")\n",
    "    print(decode(q_vec, vocab['question_idx_to_token']))\n",
    "    \n",
    "    print(\"\\n--- Original Vectorized Program (index 0) ---\")\n",
    "    print(p_vec)\n",
    "    print(\"\\n--- Decoded Program ---\")\n",
    "    print(decode(p_vec, vocab['program_idx_to_token']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All set!\n",
    "\n",
    "Our data is now preprocessed. We can move on to the first training strategy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
